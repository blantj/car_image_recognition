{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blantj/car_image_recognition/blob/main/Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_78kZvMcf-L"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSK9IFO6fSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01333669-79d5-43e5-a8ff-72cf70aea6ee"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "!pip install split_folders\n",
        "import splitfolders\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import models, layers\n",
        "from keras import optimizers, losses\n",
        "from keras.applications import DenseNet121, Xception\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split_folders in /usr/local/lib/python3.6/dist-packages (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXqo_A-ocfgO"
      },
      "source": [
        "# Obtain Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeVSGEBMh1Nf"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy5Qbefbhy0h",
        "outputId": "a4935583-59a5-42dc-ea30-5ff5dd71d91b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPBQTQN4cqqg"
      },
      "source": [
        "Unzip car image recognition dataset files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TScAapxdZPe7"
      },
      "source": [
        "!tar --gunzip --extract --verbose --file=/content/drive/MyDrive/Car_image_recognition/car_devkit.tgz\n",
        "!tar --gunzip --extract --verbose --file=/content/drive/MyDrive/Car_image_recognition/cars_test.tgz\n",
        "!tar --gunzip --extract --verbose --file=/content/drive/MyDrive/Car_image_recognition/cars_train.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCq_9UFZQn1k"
      },
      "source": [
        "# Scrub Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDLNCzO3lunK"
      },
      "source": [
        "Split image files into seperate folders for each class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inEVt-GTluN4",
        "outputId": "130be84a-f2b9-4c64-af12-bc0c630953de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "os.mkdir(f'/content/cars_train/pre-split/')\n",
        "for num in range(1,197):\n",
        "  os.mkdir(f'/content/cars_train/pre-split/{num}')\n",
        "\n",
        "annotations = scipy.io.loadmat('/content/devkit/cars_train_annos.mat')['annotations'][0]\n",
        "for index, annotation in enumerate(annotations):\n",
        "  im_class = annotation[4][0][0]\n",
        "  im_name = str(index+1).zfill(5) + '.jpg'\n",
        "  shutil.move(f'/content/cars_train/{im_name}', f'/content/cars_train/pre-split/{im_class}/{im_name}')\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-661032e17328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/cars_train/pre-split/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m197\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/cars_train/pre-split/{num}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/devkit/cars_train_annos.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/cars_train/pre-split/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8igEVjkmEgcl"
      },
      "source": [
        "Split dataset into train, test and validation folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMH5zCsXEglZ"
      },
      "source": [
        "input_folder = '/content/cars_train/pre-split'\n",
        "output_folder = '/content/cars_train/post-split'\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=37, ratio=(.64, .2, .16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP0oh3KfEgtC"
      },
      "source": [
        "Count number of images in training, test and val sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbT7oZ2EEg5_"
      },
      "source": [
        "train_folder = '/content/cars_train/post-split/train'\n",
        "test_folder = '/content/cars_train/post-split/test'\n",
        "val_folder = '/content/cars_train/post-split/val'\n",
        "\n",
        "train_imgs = []\n",
        "test_imgs = []\n",
        "val_imgs = []\n",
        "\n",
        "\n",
        "for img_class in range(1,197):\n",
        "  train_imgs.extend([file for file in os.listdir(train_folder+'/'+str(img_class)) if file.endswith('.jpg')])\n",
        "  test_imgs.extend([file for file in os.listdir(test_folder+'/'+str(img_class)) if file.endswith('.jpg')])\n",
        "  val_imgs.extend([file for file in os.listdir(val_folder+'/'+str(img_class)) if file.endswith('.jpg')]) \n",
        "\n",
        "train_batch_size = len(train_imgs)\n",
        "test_batch_size = len(test_imgs)\n",
        "val_batch_size = len(val_imgs)\n",
        "\n",
        "print('Train batch size:', train_batch_size)\n",
        "print('Test batch size:', test_batch_size)\n",
        "print('Val batch size:', val_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA3_OP_11hN3"
      },
      "source": [
        "Generate image data from .jpg files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNNoppP-XZB8"
      },
      "source": [
        "train_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        train_folder, target_size=(224, 224), batch_size = train_batch_size)\n",
        "\n",
        "test_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        test_folder, target_size=(224, 224), batch_size = test_batch_size) \n",
        "\n",
        "val_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        val_folder, target_size=(224, 224), batch_size = val_batch_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDW_HYRRLhNl"
      },
      "source": [
        "Split image data into image and label variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kat1brd9bDYp"
      },
      "source": [
        "train_images, train_labels = next(train_generator)\n",
        "test_images, test_labels = next(test_generator)\n",
        "val_images, val_labels = next(val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnZj5BjDN7H5"
      },
      "source": [
        "# Explore Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5_ol2bRN83N"
      },
      "source": [
        "Calculate shape of train, test and val image sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRUQKrgdl5Jm",
        "outputId": "05ccc23e-c228-4da7-f817-40614603f5cc"
      },
      "source": [
        "print('Train images shape: ', train_images.shape)\n",
        "print('Test images shape: ', test_images.shape)\n",
        "print('Val images shape: ', val_images.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images shape:  (5108, 224, 224, 3)\n",
            "Test images shape:  (1490, 224, 224, 3)\n",
            "Val images shape:  (1546, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fohtRcbLQRov"
      },
      "source": [
        "Calculate shape of train, test and val labels sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk3jZM0GmcfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379cb42a-f5a4-4ea9-f9a2-fd534cb93811"
      },
      "source": [
        "print('Train labels shape: ', train_labels.shape)\n",
        "print('Test labels shape: ', test_labels.shape)\n",
        "print('Val labels shape: ', val_labels.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train labels shape:  (5108, 196)\n",
            "Test labels shape:  (1490, 196)\n",
            "Val labels shape:  (1546, 196)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EnqD8WOQZIj"
      },
      "source": [
        "Calculate class balance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYYk2v_8rtT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "outputId": "ddc6075c-daec-4acc-9c3f-7ee726de5a2e"
      },
      "source": [
        "im_classes = []\n",
        "for image in scipy.io.loadmat('/content/devkit/cars_train_annos.mat')['annotations'][0]:\n",
        "  im_classes.append(image[4][0][0])\n",
        "class_df = pd.DataFrame(data=im_classes, columns=['Class'])\n",
        "\n",
        "print(class_df.reset_index().groupby('Class').count()['index'].sort_values(ascending=False))\n",
        "print('Average Class Size', (train_batch_size+test_batch_size+val_batch_size)/196)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.countplot(data=class_df, x='Class', ax=ax)\n",
        "ax.set_title('Car Image Class Distribution', fontsize=20)\n",
        "ax.set_xlabel('Class', fontsize=15)\n",
        "ax.set_ylabel('Count', fontsize=15)\n",
        "ax.set_xticklabels(labels=[])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class\n",
            "119    68\n",
            "79     49\n",
            "161    48\n",
            "167    48\n",
            "56     47\n",
            "       ..\n",
            "175    31\n",
            "64     30\n",
            "158    29\n",
            "99     28\n",
            "136    24\n",
            "Name: index, Length: 196, dtype: int64\n",
            "Average Class Size 41.55102040816327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiIxnGM-WA0X"
      },
      "source": [
        "# Model Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UAZc9FzhEkG"
      },
      "source": [
        "Build neural network in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5MBkldFy90S"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                        input_shape=(224 ,224,  3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.SpatialDropout2D(0.1))\n",
        "\n",
        "model.add(layers.Conv2D(256, (4, 4), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.SpatialDropout2D(0.1))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(196, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbkXYq6XhIw6"
      },
      "source": [
        "Train Keras Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4otN93ROfG",
        "outputId": "b00ad449-8990-400f-b518-0c73b0d9cc43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "history = model.fit(train_images,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[es])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 45s 267ms/step - loss: 113.2184 - acc: 0.0018 - val_loss: 5.2775 - val_acc: 0.0060\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 5.2783 - acc: 0.0040 - val_loss: 5.2779 - val_acc: 0.0054\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 5.2753 - acc: 0.0107 - val_loss: 5.2737 - val_acc: 0.0087\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 5.2111 - acc: 0.0259 - val_loss: 5.3360 - val_acc: 0.0081\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 5.0480 - acc: 0.0618 - val_loss: 5.4724 - val_acc: 0.0094\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIDH6e6v6iSx"
      },
      "source": [
        "Create DenseNet121 pre-trained transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlshJ5LdfQPW"
      },
      "source": [
        "pre_model = DenseNet121(\n",
        "    input_shape=train_images.shape[1:],\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\")\n",
        "pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfgB31SW6pBx"
      },
      "source": [
        "Add trained layers to DenseNet121 pre-trained layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngy-t5dV24OR"
      },
      "source": [
        "output = pre_model.output\n",
        "output = layers.GlobalAveragePooling2D()(output)\n",
        "output = layers.Dense(512, activation='relu')(output) \n",
        "output = layers.Dropout(0.0)(output) \n",
        "output = layers.Dense(196, activation='softmax')(output)\n",
        "\n",
        "model=Model(inputs=pre_model.input,outputs=output)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7nKyhT96w-K"
      },
      "source": [
        "Fit DenseNet121 transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOCup4NYF8gu",
        "outputId": "2d508d98-9cf7-412c-e375-0def38654959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "history = model.fit(train_images,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[es])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "320/320 [==============================] - 54s 126ms/step - loss: 5.3588 - accuracy: 0.0067 - val_loss: 5.2775 - val_accuracy: 0.0081\n",
            "Epoch 2/20\n",
            "320/320 [==============================] - 38s 119ms/step - loss: 5.2781 - accuracy: 0.0076 - val_loss: 5.2763 - val_accuracy: 0.0087\n",
            "Epoch 3/20\n",
            "320/320 [==============================] - 38s 119ms/step - loss: 5.2767 - accuracy: 0.0099 - val_loss: 5.2757 - val_accuracy: 0.0087\n",
            "Epoch 4/20\n",
            "320/320 [==============================] - 38s 119ms/step - loss: 5.2761 - accuracy: 0.0077 - val_loss: 5.2753 - val_accuracy: 0.0087\n",
            "Epoch 5/20\n",
            "320/320 [==============================] - 38s 119ms/step - loss: 5.2760 - accuracy: 0.0080 - val_loss: 5.2755 - val_accuracy: 0.0087\n",
            "Epoch 6/20\n",
            "320/320 [==============================] - 38s 119ms/step - loss: 5.2754 - accuracy: 0.0102 - val_loss: 6.1206 - val_accuracy: 0.0020\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvW4aQU462du"
      },
      "source": [
        "Generate image data with 299x299 size for use in Xception transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FbPS9FGwxL8",
        "outputId": "85857221-35af-42ef-c73c-2f7114e92f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xception_train_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        train_folder, target_size=(299, 299), batch_size = train_batch_size)\n",
        "\n",
        "Xception_test_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        test_folder, target_size=(299, 299), batch_size = test_batch_size) \n",
        "\n",
        "Xception_val_generator = ImageDataGenerator().flow_from_directory(\n",
        "                        val_folder, target_size=(299, 299), batch_size = val_batch_size) "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5108 images belonging to 196 classes.\n",
            "Found 1490 images belonging to 196 classes.\n",
            "Found 1546 images belonging to 196 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnaLnME37Emd"
      },
      "source": [
        "Split Xception image data into image and label variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEBi9mD6wxO0"
      },
      "source": [
        "Xception_train_images, Xception_train_labels = next(Xception_train_generator)\n",
        "Xception_test_images, Xception_test_labels = next(Xception_test_generator)\n",
        "Xception_val_images, Xception_val_labels = next(Xception_val_generator)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbKo3wnh7NPj"
      },
      "source": [
        "Create Xception pre-trained transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFHQj6wMwxQ-"
      },
      "source": [
        "Xception_pre_model = Xception(\n",
        "    input_shape=(299,299,3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\")\n",
        "Xception_pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bss3KrHe7ZTm"
      },
      "source": [
        "Add trained layers to Xception pre-trained layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPIctDDhwxTR"
      },
      "source": [
        "Xception_output = Xception_pre_model.output\n",
        "Xception_output = layers.GlobalAveragePooling2D()(Xception_output)\n",
        "Xception_output = layers.Dense(512, activation='relu')(Xception_output) \n",
        "Xception_output = layers.Dropout(0.275)(Xception_output) \n",
        "Xception_output = layers.Dense(196, activation='softmax')(Xception_output)\n",
        "\n",
        "Xception_model=Model(inputs=Xception_pre_model.input,outputs=Xception_output)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9DEJeXJ7vWE"
      },
      "source": [
        "Fit Xception transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd2tBWs-yBbi",
        "outputId": "68a88d0a-da2f-444c-d1fe-3be774e70253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xception_model.compile(optimizer='Adam',loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "Xception_es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
        "Xception_history = Xception_model.fit(Xception_train_images,\n",
        "                    Xception_train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(Xception_test_images, Xception_test_labels),\n",
        "                    callbacks=[Xception_es])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "320/320 [==============================] - 134s 401ms/step - loss: 0.0032 - accuracy: 0.9205 - val_loss: 0.0196 - val_accuracy: 0.4732\n",
            "Epoch 2/50\n",
            "320/320 [==============================] - 127s 398ms/step - loss: 0.0029 - accuracy: 0.9226 - val_loss: 0.0163 - val_accuracy: 0.5369\n",
            "Epoch 3/50\n",
            "320/320 [==============================] - 127s 398ms/step - loss: 0.0030 - accuracy: 0.9254 - val_loss: 0.0143 - val_accuracy: 0.6161\n",
            "Epoch 4/50\n",
            "320/320 [==============================] - 127s 398ms/step - loss: 0.0021 - accuracy: 0.9570 - val_loss: 0.0214 - val_accuracy: 0.5356\n",
            "Epoch 5/50\n",
            "320/320 [==============================] - 127s 398ms/step - loss: 0.0020 - accuracy: 0.9508 - val_loss: 0.0198 - val_accuracy: 0.5490\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpfrMNXoyekj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}